/**
 * Copyright 2015 Yahoo Inc. Licensed under the Apache License, Version 2.0
 * See accompanying LICENSE file.
 */

package controllers

import javax.inject.Inject

import features.ApplicationFeatures
import models.navigation.Menus
import play.api.i18n.{MessagesApi, I18nSupport}
import play.api.mvc._
import play.api.Logger
import play.api.libs.json._
import play.api.Play.current
import play.api.Configuration

import com.typesafe.config.{ConfigFactory, Config}

import scala.concurrent.{ExecutionContext, Future, Await}
import scala.concurrent.duration._
import scala.util.{Failure, Success, Try}
import scala.util.control.Breaks._

import scalaz.{-\/, \/, \/-}

import kafka.manager._
import kafka.manager.model._
import kafka.manager.model.ActorModel._

import play.api.libs.ws._
import play.api.libs.ws.ning._
import play.api.libs.json._

import org.apache.curator.framework._
import org.apache.curator.retry.BoundedExponentialBackoffRetry
import org.apache.curator.framework.recipes.cache._

import scala.collection.JavaConversions._
import scala.collection.concurrent.TrieMap
import scala.collection.mutable

import java.util.Date

import com.redis._

import QBusUtil._
/**
 * @author hiral
 */

case class QBusRedisConfig(ip: String, port: Int, passwd: String, expaire: Int, timeout: Int) {
  var redisIp: String = ip
  var redisPort: Int = port
  var redisPasswd: String = passwd
  var redisExpaire: Int = expaire
  var redisTimeout: Int = timeout

  def check(): Boolean = {
    return (redisIp != "" && redisPort > 0)
  }
}

object QBusLogCollect {
  val QBusLogCollectRedisIp = "kafka-manager.qbus-logcollect-redies-ip"
  val QBusLogCollectRedisPort = "kafka-manager.qbus-logcollect-redies-port"
  val QBusLogCollectRedisPwd = "kafka-manager.qbus-logcollect-redies-pwd"
  val QBusLogCollectRedisTimeout = "kafka-manager.qbus-logcollect-redies-timeout"
  val QBusLogCollectExpaire = "kafka-manager.qbus-logcollect-expaire"
  val QBusLogCollectHulkUrl = "kafka-manager.qbus-logcollect-hulk-url"
  val QBusLogCollectQconfList = "kafka-manager.qbus-logcollect-qconf-list"
  val QBusLogCollectHulkUrlForGetTopicProducers = "kafka-manager.qbus-logcollect-hulk-url-for-get-topic-producers"
  
  val QBusLogCollectNofile = "nofile"

  val DefaultConfig: Config = {
    val defaults: Map[String, _ <: AnyRef] = Map(
      QBusLogCollectRedisIp -> "",
      QBusLogCollectRedisPort -> "0",
      QBusLogCollectRedisPwd -> "",
      QBusLogCollectRedisTimeout -> "2000",
      QBusLogCollectExpaire -> "3600",
      QBusLogCollectHulkUrl -> "http://api.v3.hulk.corp.qihoo.net",
      QBusLogCollectHulkUrlForGetTopicProducers  -> "/?router=mix/qbus/api/topic/get-topic-producers"
    )
    import scala.collection.JavaConverters._
    ConfigFactory.parseMap(defaults.asJava)
  }
}

import QBusLogCollect._
class QBusLogCollect (val messagesApi: MessagesApi,
  val kafkaManagerContext: KafkaManagerContext,
  configuration: Configuration)
                  (implicit af: ApplicationFeatures, menus: Menus) extends Controller with I18nSupport {

  val logger: Logger = Logger("kafka.manager")
  val zkQueryUrl:String = "http://qconf-conf.add.corp.qihoo.net:8360/qconf-http/QconfHttp.php"
  import play.api.libs.concurrent.Execution.Implicits.defaultContext

  val config: Config = configuration.underlying
  private[this] val configWithDefaults = config.withFallback(DefaultConfig)
  val qbusRedisConfig = QBusRedisConfig(configWithDefaults.getString(QBusLogCollectRedisIp),
    configWithDefaults.getInt(QBusLogCollectRedisPort),
    configWithDefaults.getString(QBusLogCollectRedisPwd),
    configWithDefaults.getInt(QBusLogCollectExpaire),
    configWithDefaults.getInt(QBusLogCollectRedisTimeout))

  val qbusHulkForGetTopicProducersUrl = configWithDefaults.getString(QBusLogCollectHulkUrl) + configWithDefaults.getString(QBusLogCollectHulkUrlForGetTopicProducers)

  def getQconfArray() : List[String] = {
    import scala.collection.JavaConverters._
    var qconfArrayDefault = List("corp", "bjyt", "zzzc", "gzst")
    val qconArray: Option[List[String]] = Try(configWithDefaults.getStringList(QBusLogCollectQconfList).asScala.toList).toOption

    qconArray.getOrElse(qconfArrayDefault)
  }

  var qconfArray = getQconfArray() 
  
  case class LogStashFileInfo(path:String, startPosition:String, switch:String, useRedis:Boolean = false) 
  private[this] val kafkaManager = kafkaManagerContext.getKafkaManager

  def addLogCollectConfigByHostname(hostname:String) = Action.async(parse.tolerantJson) { request =>
    var result = ""

    /*
    var hostname = (request.body \ "hostname").validate[String].getOrElse("") 
    var cluster = (request.body \ "cluster").validate[String].getOrElse("")
    var topic = (request.body \ "topic").validate[String].getOrElse("")
    var pathList = (request.body \ "path").validate[Array[String]].getOrElse(Array[String]())
    */

    if (hostname != "" ) {
      var requestData = request.body.toString + " | " + hostname
       
      //result = "{\"errcode\":\"Ok\",\"errmsg\":\"\"}" 
      result = requestData
    } else {
      result = "{\"errcode\":\"Failed\",\"errmsg\":\"\"}"
    }
    
    scala.concurrent.Future{
      Ok(result)
    }
  }

  def getCurrentTime(): Long = {  
    val now = new Date()
    val a = now.getTime  
    var str = a + ""  
    str.substring(0,10).toLong  
  }

  def getLogCollect(clustername:String, topic:String) = Action.async { request =>
    var result: String = ""

    var logStashTreeCacheInit = false
    val logStashTreeCacheListener = new TreeCacheListener {
      override def childEvent(client: CuratorFramework, event: TreeCacheEvent): Unit = {
        event.getType match {
          case TreeCacheEvent.Type.INITIALIZED =>
            logStashTreeCacheInit = true
          case _ =>
            //do nothing
        }
      }
    }

    val zk_list = QBusUtil.getZkListByClusterName(clustername)
    if (zk_list != "") {
    val curator: CuratorFramework = CuratorFrameworkFactory.newClient(
      zk_list,
      new BoundedExponentialBackoffRetry(1000, 3000, 3))
    curator.start()
    val logStashTreeCache = new TreeCache(curator, "/logstash")
    logStashTreeCache.start()
    logStashTreeCache.getListenable.addListener(logStashTreeCacheListener)

    while (!logStashTreeCacheInit) {
      Thread.sleep(100)
    }

    var logStashInfoList:Map[String, List[LogStashFileInfo]] = Map()

    Option(logStashTreeCache.getCurrentChildren("/logstash")).map(machineList =>{
      for ((k,v) <- machineList) {
        var fileConfigList:List[LogStashFileInfo] = List()

        var data = Option(logStashTreeCache.getCurrentData("/logstash" + "/" + k + "/" + "config")).flatMap(currentData => 
            Option(currentData.getData)).map(asString).getOrElse("")
          //logger.info("xxx | config | path | " + "/logstash" + "/" + k + "/" + "config | " + data)
          try {
            val dataJson: JsValue = Json.parse(data)
            dataJson.asOpt[List[Map[String, String]]].map(configList => {
              var newConfigList = configList.filter(_.getOrElse("topic_id", "") == topic)
              for (i <- 0 until newConfigList.size) {
                fileConfigList = fileConfigList :+ new LogStashFileInfo(newConfigList(i).getOrElse("path", ""),
                  newConfigList(i).getOrElse("start_position", ""),
                  newConfigList(i).getOrElse("switch", "on"))
              }
            })
          } catch {
            case e: Exception =>
              logger.info("xxx | get fileconfig list exception:")
              e.printStackTrace()
          }

        if (fileConfigList.size > 0) {
          logStashInfoList += (k -> fileConfigList)
        }
      }
      ""
    })

    result = "{\"errcode\":\"Ok\", \"errmsg\":\"\","
    result += "\"result\":{"
    var k = 0
    for ((machine, fileConfigList) <- logStashInfoList) {
      if (k != 0) {
        result += ","
      }
      k += 1

      result += "\"" + machine + "\":{"
      for (i <- 0 until fileConfigList.size) {
        if (i != 0) {
          result += ","
        }

        result += "\"" + fileConfigList(i).path + "\":" + "{"
        result += "\"start_position\":" + "\"" + fileConfigList(i).startPosition + "\","
        result += "\"switch\":" + "\"" + fileConfigList(i).switch + "\","
        result += "\"file_list\":["

        var data = "error" 
        try {
          Option(logStashTreeCache.getCurrentData("/logstash" + "/" + machine + "/offset/" + fileConfigList(i).path.replace("/", "|"))) match {
            case Some(currentData) => data = Option(currentData.getData).map(asString).getOrElse("")
            case None => data = "error"
          }
        } catch {
          case e: Exception =>
            data = "error"
            e.printStackTrace()
        }

        if (data != "" && data != "error") {
          result += data
        } else if (data == ""){
          result += "{}"
        }

        result += "]"

        result += "}"
      }

      result += "}"
    }

    result += "}"
    result += "}"

    Try(logStashTreeCache.getListenable.removeListener(logStashTreeCacheListener))
    Try(logStashTreeCache.close())
    Try(curator.close())
    } else {
        logger.info("Not found cluster: " + clustername)
        result = "{" + "\"errcode\":\"Failed\", \"errmsg\":\"not found cluster:" + clustername + "\"}"
    }

    scala.concurrent.Future{
      Ok(result)
    }
  }

  def getLogCollectEx(clustername:String, topic:String) = Action.async { request =>
    var result: String = ""

    var logStashTreeCacheInit = false
    val logStashTreeCacheListener = new TreeCacheListener {
      override def childEvent(client: CuratorFramework, event: TreeCacheEvent): Unit = {
        event.getType match {
          case TreeCacheEvent.Type.INITIALIZED =>
            logStashTreeCacheInit = true
          case _ =>
            //do nothing
        }
      }
    }

    val zk_list = QBusUtil.getZkListByClusterName(clustername)
    if (zk_list != "") {
    val curator: CuratorFramework = CuratorFrameworkFactory.newClient(
      zk_list,
      new BoundedExponentialBackoffRetry(1000, 3000, 3))
    curator.start()
    val logStashTreeCache = new TreeCache(curator, "/logstash")
    logStashTreeCache.start()
    logStashTreeCache.getListenable.addListener(logStashTreeCacheListener)

    while (!logStashTreeCacheInit) {
      Thread.sleep(100)
    }

    var logStashInfoList:Map[String, List[LogStashFileInfo]] = Map()

    var machineList = QBusUtil.getLogMachineListByTopic(clustername, topic, qbusHulkForGetTopicProducersUrl)
    for (k <- machineList) {
      var fileConfigList:List[LogStashFileInfo] = List()

      var data = Option(logStashTreeCache.getCurrentData("/logstash" + "/" + k + "/" + "config")).flatMap(currentData => 
          Option(currentData.getData)).map(asString).getOrElse("")
      logger.info("xxx | config | path | " + "/logstash" + "/" + k + "/" + "config | " + data)
      try {
        val dataJson: JsValue = Json.parse(data)
        dataJson.asOpt[List[Map[String, String]]].map(configList => {
          var newConfigList = configList.filter(_.getOrElse("topic_id", "") == topic)
          for (i <- 0 until newConfigList.size) {
            fileConfigList = fileConfigList :+ new LogStashFileInfo(newConfigList(i).getOrElse("path", ""),
              newConfigList(i).getOrElse("start_position", ""),
              newConfigList(i).getOrElse("switch", "on"))
          }
        })
      } catch {
        case e: Exception =>
          logger.info("Failed to parse json | data: " + data + " | exception: " + e)
      }

      if (fileConfigList.size > 0) {
        logStashInfoList += (k -> fileConfigList)
      }
    }

    result = "{\"errcode\":\"Ok\", \"errmsg\":\"\","
    result += "\"result\":{"
    var k = 0
    for ((machine, fileConfigList) <- logStashInfoList) {
      if (k != 0) {
        result += ","
      }
      k += 1

      result += "\"" + machine + "\":{"
      for (i <- 0 until fileConfigList.size) {
        if (i != 0) {
          result += ","
        }

        result += "\"" + fileConfigList(i).path + "\":" + "{"
        result += "\"start_position\":" + "\"" + fileConfigList(i).startPosition + "\","
        result += "\"switch\":" + "\"" + fileConfigList(i).switch + "\","
        result += "\"file_list\":["

        var data = "error" 
        try {
          Option(logStashTreeCache.getCurrentData("/logstash" + "/" + machine + "/offset/" + fileConfigList(i).path.replace("/", "|"))) match {
            case Some(currentData) => data = Option(currentData.getData).map(asString).getOrElse("")
            case None => data = "error"
          }
        } catch {
          case e: Exception =>
            data = "error"
        }

        if (data != "" && data != "error") {
          result += data
        } else if (data == ""){
          result += "{}"
        }

        result += "]"

        result += "}"
      }

      result += "}"
    }

    result += "}"
    result += "}"

    Try(logStashTreeCache.getListenable.removeListener(logStashTreeCacheListener))
    Try(logStashTreeCache.close())
    Try(curator.close())
    } else {
        logger.info("Not found cluster: " + clustername)
        result = "{" + "\"errcode\":\"Failed\", \"errmsg\":\"not found cluster:" + clustername + "\"}"
    }

    scala.concurrent.Future{
      Ok(result)
    }
  }

  def getLogCollectV2(clustername:String, topic:String) = Action.async { request =>
    var result: String = ""

    var logStashTreeCacheInit = false
    val logStashTreeCacheListener = new TreeCacheListener {
      override def childEvent(client: CuratorFramework, event: TreeCacheEvent): Unit = {
        event.getType match {
          case TreeCacheEvent.Type.INITIALIZED =>
            logStashTreeCacheInit = true
          case _ =>
            //do nothing
        }
      }
    }

    var curator: CuratorFramework = null 
    var logStashTreeCache: TreeCache = null 

    val zk_list = QBusUtil.getZkListByClusterName(clustername)
    if (zk_list != "") {
      curator = CuratorFrameworkFactory.newClient(
        zk_list,
        new BoundedExponentialBackoffRetry(1000, 3000, 3))
      curator.start()
      logStashTreeCache = new TreeCache(curator, "/logstash")
      logStashTreeCache.start()
      logStashTreeCache.getListenable.addListener(logStashTreeCacheListener)

      while (!logStashTreeCacheInit) {
        Thread.sleep(100)
      }
      } else {
        logger.info("Not found cluster: " + clustername)
        //result = "{" + "\"errcode\":\"Failed\", \"errmsg\":\"not found cluster:" + clustername + "\"}"
    }

    var logStashInfoList:Map[String, List[LogStashFileInfo]] = Map()

    var machineList = QBusUtil.getLogMachineListByTopic(clustername, topic, qbusHulkForGetTopicProducersUrl)

    // 获取topic对应的收集机器列表和path
    var useQconf = true
    for (k <- machineList) {
      // 从qconf取配置
       //logger.info("CCC: " + k)
      var fileConfigList:List[LogStashFileInfo] = List[LogStashFileInfo]()
      if (useQconf) {
        fileConfigList = getLogCollectConfigFromQconf(clustername, k, topic)
      }

      if (fileConfigList.isEmpty()) {
        if (k.startsWith("w-")) {
           var machineName = k.substring(2)
          fileConfigList = getLogCollectConfigFromQconf(clustername, machineName, topic)
        }
      }

      // 从qconf取不到从zk上取,兼容老版本
      // 兼容的使命已完成,下面的代码没用了
      //if (fileConfigList.size == 0) {
      /*
      if (false) {
        //logger.info("VVVV: " + k)
          // 如果首次从Qconf获取配置失败,则后续不再从Qconf获取
          useQconf = false

          var data = Option(logStashTreeCache.getCurrentData("/logstash" + "/" + k + "/" + "config")).flatMap(currentData => 
              Option(currentData.getData)).map(asString).getOrElse("")
          try {
            val dataJson: JsValue = Json.parse(data)
            dataJson.asOpt[List[Map[String, String]]].map(configList => {
              var newConfigList = configList.filter(_.getOrElse("topic_id", "") == topic)
              for (i <- 0 until newConfigList.size) {
                fileConfigList = fileConfigList :+ new LogStashFileInfo(newConfigList(i).getOrElse("path", ""),
                  newConfigList(i).getOrElse("start_position", ""),
                  newConfigList(i).getOrElse("switch", "on"),
                  false)
              }
            })
          } catch {
            case e: Exception =>
              logger.info("Failed to parse json | data: " + data + " | exception: " + e)
          }
      } 
       logger.info("CCC: " + fileConfigList)
      */

      if (fileConfigList.size > 0) {
        logStashInfoList += (k -> fileConfigList)
      }
    }

    // 初始化获取收集进度的redids实例
    var redisClient: Option[RedisClient] = None                                
    if (logStashInfoList.size > 0) {
      if (qbusRedisConfig.check()) {                                             
        redisClient = Some(new RedisClient(qbusRedisConfig.redisIp,              
          qbusRedisConfig.redisPort,                                             
          0,                                                                     
          Some(qbusRedisConfig.redisPasswd),                                     
          qbusRedisConfig.redisTimeout))                                                                    
      } else {                                                                   
        var clusterInfo = QBusUtil.getRedisInfoByClusterName(clustername)        
        if (clusterInfo != "") {                                                 
          var redisInfos = clusterInfo.split("\\|")                              
          if (redisInfos.length == 3) {                                          
            redisClient = Some(new RedisClient(redisInfos(0),                    
              Integer.parseInt(redisInfos(1)),                                   
              0,                                                                 
              Some(redisInfos(2)),                                               
              qbusRedisConfig.redisTimeout))                                                                
          } else {                                                               
            logger.info("QBusLogCollect | split | Redis infor is invalid")               
          }                                                                      
          } else {                                                                 
            logger.info("QBusLogCollect | Redis infor is invalid")               
          }                                                                        
      }                                                                          
    }

    result = "{\"errcode\":\"Ok\", \"errmsg\":\"\","
    result += "\"result\":{"
    var k = 0
    for ((machine, fileConfigList) <- logStashInfoList) {
      if (k != 0) {
        result += ","
      }
      k += 1

      result += "\"" + machine + "\":{"
      for (i <- 0 until fileConfigList.size) {
        if (i != 0) {
          result += ","
        }

        result += "\"" + fileConfigList(i).path + "\":" + "{"
        result += "\"start_position\":" + "\"" + fileConfigList(i).startPosition + "\","
        result += "\"switch\":" + "\"" + fileConfigList(i).switch + "\","
        result += "\"file_list\":["

        var data = "error" 

        var noFileFlag = false 

        //logger.info("BBBB: " + fileConfigList(i).useRedis + " | machine: " + machine)
        // 从redis上获取文件收集进度
        if (fileConfigList(i).useRedis) {
          try {
            if (redisClient.isDefined) {
              var redisData = redisClient.get.get(clustername + "|" + machine + "|" + fileConfigList(i).path).getOrElse("")
              if (redisData == "") {
                if (machine.startsWith("w-")) {
                  var machineName = machine.substring(2)
                  redisData = redisClient.get.get(clustername + "|" + machineName + "|" + fileConfigList(i).path).getOrElse("")
                }
              }

              if (redisData != "") {
                if (redisData == QBusLogCollectNofile) {
                  data = ""
                  noFileFlag = true
                } else {
                  var redisInfos = redisData.split("\\|")
                  data = redisInfos(0)
                 //if (getCurrentTime - Integer.parseInt(redisInfos(1)) < qbusRedisConfig.redisExpaire) {
                 //  data = redisInfos(0)
                 //} else {
                 //  data = ""
                 //}
                }
              }
            }
          } catch {
            case e: Exception =>
              data = "error"
          }
        } else {
          // 从zk上获取文件收集进度
          try {
            Option(logStashTreeCache.getCurrentData("/logstash" + "/" + machine + "/offset/" + fileConfigList(i).path.replace("/", "|"))) match {
              case Some(currentData) => data = Option(currentData.getData).map(asString).getOrElse("")
              case None => data = "error"
            }
          } catch {
            case e: Exception =>
              data = "error"
          }
        }

        if (data != "" && data != "error") {
          result += data
        } else if (data == ""){
          result += "{}"
        }

        result += "]"

        if (noFileFlag) {
          result += ",\"no_file\":" + "\"true" + "\""
        } else {
          result += ",\"no_file\":" + "\"false" + "\""
        }

        result += "}"
      }

      result += "}"
    }

    result += "}"
    result += "}"

    if (redisClient.isDefined) {
      //Try(redisClient.close)
    }

    Try(logStashTreeCache.getListenable.removeListener(logStashTreeCacheListener))
    Try(logStashTreeCache.close())
    Try(curator.close())

    scala.concurrent.Future{
      Ok(result)
    }
  }

  def getLogCollectConfigFromQconfByIdc(qconfIdc: String, cluster: String, hostname: String, topic: String): List[LogStashFileInfo] = {
    import play.api.libs.concurrent.Execution.Implicits.defaultContext
    val logger: Logger = Logger("kafka.manager")
    val queryUrl:String = "http://qconf-conf.add.corp.qihoo.net:8360/qconf-http/QconfHttp.php"

    var fileConfigList:List[LogStashFileInfo] = List()

    val ws = NingWSClient()

    Try(Await.result(ws.url(queryUrl)
      .withHeaders("Content-type" -> "application/x-www-form-urlencoded")
      .post("func=getConf&key=/qbus2/logcollection/" + hostname + "&idc=" + qconfIdc),
      3 second)) match {
        case Success(response) =>
          var configJsonStr = response.asInstanceOf[WSResponse].body
          configJsonStr = configJsonStr.subSequence(1, configJsonStr.length - 1).toString()
          configJsonStr = configJsonStr.replace("\\\"", "\"")
          //logger.info("AAAA: " + hostname)
          //logger.info("SSSS : " + configJsonStr)

          if (configJsonStr != "" &&
            configJsonStr != "null" &&
            configJsonStr != "ul") {
              try {
                //logger.info("SSSS : 111" )
                val configJson: JsValue = Json.parse(configJsonStr)
                (configJson \ "clusters").asOpt[List[JsValue]].map {
                  configList => {
                    for (clusterInfo <- configList) {
                      var clusterNameStr = (clusterInfo \ "cluster").asOpt[String].getOrElse("")
                      if (clusterNameStr == cluster) {
                        //logger.info("SSSS : 222" )
                        (clusterInfo \ "config").asOpt[List[JsValue]].map {
                          itemList => {
                            for (m <- itemList) {
                              var topicConfig = (m \ "topic_id").asOpt[String].getOrElse("")
                              if (topic == topicConfig) {
                                var path = (m  \ "path").asOpt[String].getOrElse("")
                                var sp = (m  \ "start_position").asOpt[String].getOrElse("")
                                var switch = (m  \ "switch").asOpt[String].getOrElse("on")
                                fileConfigList = fileConfigList :+ new LogStashFileInfo(path,
                                  sp, 
                                  switch,
                                  true)
                              }
                            }
                          }
                        }
                        Try(ws.close())
                        return fileConfigList 
                      }
                    }
                  }
                }
              } catch {
                case e: Exception =>
                  Try(ws.close())
                  return fileConfigList
              }
              } else {
                Try(ws.close())
                return fileConfigList
              }

                case Failure(ex) =>
                  //logger.info("xxx | config | path | " + "/logstash" + "/" + k + "/" + "config | " + data)
      }

      Try(ws.close())

      fileConfigList
  }

  def getLogCollectConfigFromQconf(cluster: String, hostname: String, topic: String): List[LogStashFileInfo] = {
    var fileConfigList:List[LogStashFileInfo] = List[LogStashFileInfo]()
    for (qconf <- qconfArray) {
      fileConfigList = getLogCollectConfigFromQconfByIdc(qconf, cluster, hostname, topic)
      if (fileConfigList.length > 0) {
        return fileConfigList 
      }
    }

    return fileConfigList
  }

}
